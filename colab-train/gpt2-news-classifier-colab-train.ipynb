{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1fedf1",
   "metadata": {},
   "source": [
    "# Text Classification using fine-tuned GPT-2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39e215",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://www.google.com) &nbsp;[![Generic badge](https://img.shields.io/badge/GitHub-Source-greensvg)](https://github.com/haocai1992/GPT2-News-Classifier/blob/main/colab-train/gpt2-news-classifier-colab-train.ipynb) &nbsp;[![Generic badge](https://img.shields.io/badge/Article-Medium-black.svg)](https://medium.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42c176",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use a pre-trained GPT-2 model from [HuggingFace](https://huggingface.co/transformers/) to perform text classification task.\n",
    "\n",
    "Both BERT and GPT-2 are state-of-the-art transformer models (less \"SOTA\" now in 2022, with emergence of GPT-3 and other new ones...) that has phenomenal performance in many NLP tasks. One big difference between these two is that GPT-2 was built using decoder blocks, while BERT uses encoder blocks. Therefore, GPT-2 is mostly used in text-generation tasks. Unlike BERT, I couldn't find a lot of articles/tech blogs talking about using GPT-2 for **text classification** tasks. That's why I want to try that out here!\n",
    "\n",
    "The **main idea** is this: Since GPT2 is a decoder transformer, the last token of the input sequence is used to make predictions about the next token that should follow the input. This means that the last token of the input sequence can be used to for predictions in a classification task too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e5963",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1d27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "# !pip3 install pandas\n",
    "# !pip3 install numpy\n",
    "# !pip3 install sklearn\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e741e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caihao/.pyenv/versions/3.7.4/envs/news_classifier_env/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5ebf5",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f13f2b",
   "metadata": {},
   "source": [
    "The dataset we are going to use in this notebook is the *[BBC News Classification dataset](http://mlg.ucd.ie/datasets/bbc.html)*. You can download the dataset in [Kaggle](https://www.kaggle.com/c/learn-ai-bbc/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5539aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194ae8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bbc-text.csv')\n",
    "# df = pd.read_csv('./data/bbc-text-small.csv') # smaller dataset to save training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a0ebe",
   "metadata": {},
   "source": [
    "This dataset is in CSV format and it has 2126 different texts, each labeled under one of 5 categories: entertainment, sport, tech, business, or politics. It has two columns, **category** which will be the label; and **text** which will be our input data for GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531e2aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9390985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(\"category\").size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a45a7",
   "metadata": {},
   "source": [
    "## Preprocessing data (text tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97321467",
   "metadata": {},
   "source": [
    "We need to tokenize the input text in order to feed GPT-2 model with its expected data format. This can be easily done using HuggingFace Transformers' GPT2Tokenizer object. However, unlike BERT which does padding to the right, for GPT-2 we need to do padding to the left, because we need to use the last token for prediction. Therefore we need to adapt GPT2Tokenizer after calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09df6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4dc1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"I will watch Memento tonight\"\n",
    "gpt2_input = tokenizer(example_text, padding=\"max_length\", max_length=10, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a407e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256, 50256, 50256,    40,   481,  2342,   337,   972,    78,  9975]])\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe66b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_input[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee99b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|><|endoftext|>I will watch Memento tonight\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f080f7c",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c65cc",
   "metadata": {},
   "source": [
    "PyTorch provides a very convenient way to construct cusom Dataset class to facilitate model training. See more details [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). Here we will build a custom Dataset class to read in our news data, tokenize them, and store them into containers for batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b73b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "labels = {\n",
    "    \"business\": 0,\n",
    "    \"entertainment\": 1,\n",
    "    \"sport\": 2,\n",
    "    \"tech\": 3,\n",
    "    \"politics\": 4\n",
    "         }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text,\n",
    "                                padding='max_length',\n",
    "                                max_length=128,\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "        \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        # Get a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "    \n",
    "    def get_batch_texts(self, idx):\n",
    "        # Get a batch of inputs\n",
    "        return self.texts[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b70d19",
   "metadata": {},
   "source": [
    "## Split training-test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd7144",
   "metadata": {},
   "source": [
    "One more thing to do before we start with models. We need to split train, validation and test data as separate dataframes. Numpy's split function can do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa8a30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
    "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f92730",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f05f6b",
   "metadata": {},
   "source": [
    "Now comes to the most important part of this notebook. We need to buid a classifier model on top of a pre-trained GPT-2 model. The trick here is to add a linear layer on top of GPT-2's 12 layers of decoders with its output dimension equals our number of labels. In this way we can use GPT-2 to output 5 numbers which corresponds to our five news categories!\n",
    "\n",
    "For more information about how to build customized models in PyTorch, see [here](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9479c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "                input_id: encoded inputs ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        batch_size = gpt_out.shape[0]\n",
    "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1587a77d",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1195c4d",
   "metadata": {},
   "source": [
    "Now it's time to train (fine-tune) our model! Here I build a standard PyTorch training loop following [this guide](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html). Since this is a multi-class classification problem, I picked [cross-entropy-loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as our loss function (\"criterion\"), and [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) as the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc4a339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [00:51<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.233             | Train Accuracy:  0.855             | Val Loss:  0.033             | Val Accuracy:  0.982\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for val_input, val_label in val_dataloader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "                \n",
    "            print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")\n",
    "            \n",
    "EPOCHS = 1\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5dea5",
   "metadata": {},
   "source": [
    "Looks like the model is already well trained after 1 epoch! This is probably due to the fact that as a pre-trained model with gigantic number of parameters, GPT-2 is already capable of differentiating different text paragraphs without too much tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe4ba4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8de2c6",
   "metadata": {},
   "source": [
    "After model training, it's recommended to use the test data to evaluate the model performance on unseen data. I build the `evaluate` function according [this PyTorch guide](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9413304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.969\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "        \n",
    "    # Tracking variables\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            # add original labels\n",
    "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
    "            # get predicitons to list\n",
    "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    return true_labels, predictions_labels\n",
    "    \n",
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33be9b2",
   "metadata": {},
   "source": [
    "Another good gauge of model performance is the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2afbb69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f16e78c5c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels, labels=range(len(labels)), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(labels.keys()))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939518c5",
   "metadata": {},
   "source": [
    "## Saving and loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e261b",
   "metadata": {},
   "source": [
    "After training, we need to save the model locally. PyTorch models store the learned parameters in an internal state dictionary, called state_dict. These can be persisted via the torch.save method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6104415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "# torch.save(model.state_dict(), \"./model/gpt2-text-classifier-model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df99a7",
   "metadata": {},
   "source": [
    "To load model weights, you need to create an instance of the same model first, and then load the parameters using load_state_dict() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afcc233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleGPT2SequenceClassifier(\n",
       "  (gpt2model): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=98304, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "model_new = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
    "model_new.load_state_dict(torch.load(\"./model/gpt2-text-classifier-model.pt\"))\n",
    "model_new.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c487cf5",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacec035",
   "metadata": {},
   "source": [
    "Here we want to use the model to generate inferences. Here we use a clipped news from [BBC Politics](https://www.bbc.com/news/uk-60095459) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c599d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the uk has accused president putin of plotting to install a pro-moscow figure to lead ukraine's government. the foreign office took the unusual step of naming former ukrainian mp yevhen murayev as a potential kremlin candidate. russia has moved 100,000 troops near to its border with ukraine but denies it is planning an invasion. uk ministers have warned that the russian government will face serious consequences if there is an incursion. in a statement, foreign secretary liz truss said: \"the information being released today shines a light on the extent of russian activity designed to subvert ukraine, and is an insight into kremlin thinking. \"russia must de-escalate, end its campaigns of aggression and disinformation, and pursue a path of diplomacy.\" the russian ministry of foreign affairs tweeted that the foreign office was \"circulating disinformation\" and urged it to \"cease these provocative activities\" and \"stop spreading nonsense\".\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "The UK has accused President Putin of plotting to install a pro-Moscow figure to lead Ukraine's government.\n",
    "\n",
    "The Foreign Office took the unusual step of naming former Ukrainian MP Yevhen Murayev as a potential Kremlin candidate.\n",
    "\n",
    "Russia has moved 100,000 troops near to its border with Ukraine but denies it is planning an invasion.\n",
    "\n",
    "UK ministers have warned that the Russian government will face serious consequences if there is an incursion.\n",
    "\n",
    "In a statement, Foreign Secretary Liz Truss said: \"The information being released today shines a light on the extent of Russian activity designed to subvert Ukraine, and is an insight into Kremlin thinking.\n",
    "\n",
    "\"Russia must de-escalate, end its campaigns of aggression and disinformation, and pursue a path of diplomacy.\"\n",
    "\n",
    "The Russian Ministry of Foreign Affairs tweeted that the Foreign Office was \"circulating disinformation\" and urged it to \"cease these provocative activities\" and \"stop spreading nonsense\".\n",
    "\n",
    "\"\"\"\n",
    "fixed_text = \" \".join(example_text.lower().split())\n",
    "print(fixed_text)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_input = tokenizer(fixed_text, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcf6a3",
   "metadata": {},
   "source": [
    "After text tokenization, we need to extract two inputs for the model, `input_id` and `mask`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9319acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = model_input['attention_mask'].cpu()\n",
    "input_id = model_input[\"input_ids\"].squeeze(1).cpu()\n",
    "\n",
    "output = model_new(input_id, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019ee362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4280, -3.0708,  0.4508, -1.4243,  6.4141]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860e64b",
   "metadata": {},
   "source": [
    "The output here is the model output for each label. We can normalize them as probabilities using Softmax algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4de8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(output, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ecdcc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0635e-03, 7.5684e-05, 2.5610e-03, 3.9268e-04, 9.9591e-01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369a4e1",
   "metadata": {},
   "source": [
    "Let's see if our predictor can correctly classify this news as \"politics\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ea88e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"business\",\n",
    "    1: \"entertainment\",\n",
    "    2: \"sport\",\n",
    "    3: \"tech\",\n",
    "    4: \"politics\"\n",
    "         }\n",
    "\n",
    "pred_label = labels_map[output.argmax(dim=1).item()]\n",
    "print(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525adef",
   "metadata": {},
   "source": [
    "It can!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7906ab0",
   "metadata": {},
   "source": [
    "## Clear cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cf55b",
   "metadata": {},
   "source": [
    "If you are using PyTorch's CUDA version, remember to clear cache after running this notebook to avoid re-run issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2accc441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
